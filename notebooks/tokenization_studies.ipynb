{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# Might need these later for longer strings?\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_tokenization(s) :\n",
    "    for ip in \".,/;!?'%*-\" :\n",
    "        s = s.replace(ip,\" \"+ip)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"With the Tokyo Olympics less than a year away, speculation is growing in Japan over who will be the final torchbearer to light the cauldron in the new Olympic Stadium, in the traditional ritual that begins every Games. Some predict a famous Japanese athlete, such as retired baseball player Ichiro Suzuki, will do the honors. Others say it will be an ordinary, but symbolically important, person. Picked to light the flame in 1964, the last time Tokyo hosted the Games, was Yoshinori Sakai, a 19-year-old college athlete born in Hiroshima on Aug. 6, 1945, the day of the U.S. atomic bombing - a choice meant to highlight Japan's remarkable post-war reconstruction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(s,max_len=75) :\n",
    "    tokenized_texts = []\n",
    "    if type(s)==str :\n",
    "        sentences = [s]\n",
    "    elif type(s)==list :\n",
    "        sentences = s\n",
    "    for sentence in sentences : \n",
    "        words  = []\n",
    "        for word in prep_for_tokenization(sentence).split(\" \") : # Any better way to do this?\n",
    "            # Split into tokens by spaces\n",
    "            # Now split each token into sub-tokens using the tokenizer\n",
    "            # such that any new sub-tokens receive either a \"O\" or \"I-\"\n",
    "            # label as necessary\n",
    "            token = tokenizer.tokenize(word)\n",
    "            if len(token) == 0 :\n",
    "                continue\n",
    "            words.extend(token)\n",
    "            # Control for sequence length\n",
    "            if len(words)>max_len :\n",
    "                tokenized_texts.append(words[0:max_len])\n",
    "                words = words[max_len:]            \n",
    "        tokenized_texts.append(words)\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenize_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['with',\n",
       "  'the',\n",
       "  'tokyo',\n",
       "  'olympics',\n",
       "  'less',\n",
       "  'than',\n",
       "  'a',\n",
       "  'year',\n",
       "  'away',\n",
       "  ',',\n",
       "  'speculation',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'in',\n",
       "  'japan',\n",
       "  'over',\n",
       "  'who',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'final',\n",
       "  'torch',\n",
       "  '##be',\n",
       "  '##are',\n",
       "  '##r',\n",
       "  'to',\n",
       "  'light',\n",
       "  'the',\n",
       "  'ca',\n",
       "  '##uld',\n",
       "  '##ron',\n",
       "  'in',\n",
       "  'the',\n",
       "  'new',\n",
       "  'olympic',\n",
       "  'stadium',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'traditional',\n",
       "  'ritual',\n",
       "  'that',\n",
       "  'begins',\n",
       "  'every',\n",
       "  'games',\n",
       "  '.',\n",
       "  'some',\n",
       "  'predict',\n",
       "  'a',\n",
       "  'famous',\n",
       "  'japanese',\n",
       "  'athlete',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'retired',\n",
       "  'baseball',\n",
       "  'player',\n",
       "  'ich',\n",
       "  '##iro',\n",
       "  'suzuki',\n",
       "  ',',\n",
       "  'will',\n",
       "  'do',\n",
       "  'the',\n",
       "  'honors',\n",
       "  '.',\n",
       "  'others',\n",
       "  'say',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'an',\n",
       "  'ordinary',\n",
       "  ','],\n",
       " ['but',\n",
       "  'symbolic',\n",
       "  '##ally',\n",
       "  'important',\n",
       "  ',',\n",
       "  'person',\n",
       "  '.',\n",
       "  'picked',\n",
       "  'to',\n",
       "  'light',\n",
       "  'the',\n",
       "  'flame',\n",
       "  'in',\n",
       "  '1964',\n",
       "  ',',\n",
       "  'the',\n",
       "  'last',\n",
       "  'time',\n",
       "  'tokyo',\n",
       "  'hosted',\n",
       "  'the',\n",
       "  'games',\n",
       "  ',',\n",
       "  'was',\n",
       "  'yo',\n",
       "  '##shin',\n",
       "  '##ori',\n",
       "  'sa',\n",
       "  '##kai',\n",
       "  ',',\n",
       "  'a',\n",
       "  '19',\n",
       "  '-',\n",
       "  'year',\n",
       "  '-',\n",
       "  'old',\n",
       "  'college',\n",
       "  'athlete',\n",
       "  'born',\n",
       "  'in',\n",
       "  'hiroshima',\n",
       "  'on',\n",
       "  'aug',\n",
       "  '.',\n",
       "  '6',\n",
       "  ',',\n",
       "  '1945',\n",
       "  ',',\n",
       "  'the',\n",
       "  'day',\n",
       "  'of',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'atomic',\n",
       "  'bombing',\n",
       "  'â€”',\n",
       "  'a',\n",
       "  'choice',\n",
       "  'meant',\n",
       "  'to',\n",
       "  'highlight',\n",
       "  'japan',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'remarkable',\n",
       "  'post',\n",
       "  '-',\n",
       "  'war',\n",
       "  'reconstruction',\n",
       "  '.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
