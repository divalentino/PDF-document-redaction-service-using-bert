{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OUwIqu0yaD45",
    "outputId": "fb00c5fb-4d51-43e2-ea8a-0f3d50b6e4ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He said last week 's tsunami and the massive underwater earthquake that triggered it has affected millions in Asia and Africa .\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = sorted(list(set(data[\"Tag\"].values)))\n",
    "tags_vals.append('[PAD]') \n",
    "tag2idx   = {t: i for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 0,\n",
       " 'B-eve': 1,\n",
       " 'B-geo': 2,\n",
       " 'B-gpe': 3,\n",
       " 'B-nat': 4,\n",
       " 'B-org': 5,\n",
       " 'B-per': 6,\n",
       " 'B-tim': 7,\n",
       " 'I-art': 8,\n",
       " 'I-eve': 9,\n",
       " 'I-geo': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-nat': 12,\n",
       " 'I-org': 13,\n",
       " 'I-per': 14,\n",
       " 'I-tim': 15,\n",
       " 'O': 16,\n",
       " '[PAD]': 17}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {}\n",
    "for key in list(tag2idx.keys()) :\n",
    "    idx2tag[tag2idx[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-pretrained-bert==0.4.0\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs      = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cuda\" in str(device) : \n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKBGxaXeWaC1"
   },
   "source": [
    "BERT does some weird tokenization of out-of-vocabulary words into pieces, e.g. `\"gunships\"` becomes `[ \"guns\", \"##hips\" ]`, so we need to account for that in our labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4242ed697d2c44b1b303aaa2e9488f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47959), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "labels          = []\n",
    "for sentence in tqdm(getter.sentences) :\n",
    "    # Split into tokens by spaces\n",
    "    # Now split each token into sub-tokens using the tokenizer\n",
    "    # such that any new sub-tokens receive either a \"O\" or \"I-\"\n",
    "    # label as necessary\n",
    "    words  = []\n",
    "    lls    = []\n",
    "    for i in range(len(sentence)) :\n",
    "        # Not sure why there's some whitespaces but OK\n",
    "        word  = tokenizer.tokenize(sentence[i][0])\n",
    "        if len(word) == 0 :\n",
    "            continue\n",
    "        label = [sentence[i][2]]\n",
    "        if len(word)>1 :\n",
    "            label.extend([label[0].replace(\"B-\",\"I-\")]*(len(word)-1))\n",
    "#             print(word,label)\n",
    "#             input()\n",
    "        try : \n",
    "            assert(len(word)==len(label))\n",
    "        except : \n",
    "            print(\"+\"+sentence[i][0]+\"+\")\n",
    "            print(word,label)\n",
    "            raise Exception()\n",
    "        words.extend(word)\n",
    "        lls.extend(label)\n",
    "    tokenized_texts.append(words)\n",
    "    labels.append(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgWfFPlVKI2G"
   },
   "outputs": [],
   "source": [
    "assert(len(tokenized_texts[6])==len(labels[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWsF8J9xKKfd"
   },
   "outputs": [],
   "source": [
    "# Pad with zeroes (0 = attention mask index in BERT)\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji8A-wiuKP_M"
   },
   "outputs": [],
   "source": [
    "# Not sure what the best option is for padding here\n",
    "# attention masks get ignored during loss calculation anyway - maybe not an issue?\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"[PAD]\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ARvgdN7KR47"
   },
   "outputs": [],
   "source": [
    "# Used to flag which terms are padding and which are real data\n",
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "woGvZAFnKTMD"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5QfeAGdKUfj"
   },
   "outputs": [],
   "source": [
    "tr_inputs  = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags    = torch.tensor(tr_tags)\n",
    "val_tags   = torch.tensor(val_tags)\n",
    "tr_masks   = torch.tensor(tr_masks)\n",
    "val_masks  = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvtvdBRKKWCq"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25JNhz-lKXj5"
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEYqhEX1KaW5"
   },
   "outputs": [],
   "source": [
    "if \"cuda\" in str(device) : \n",
    "  model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtv2anWEKtJ2"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "X-ANB1JqK5ZB",
    "outputId": "fe33efb9-c691-4fba-b832-89f099d464ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.17.5)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.2.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1m4rAxsKzGq"
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels, pad_index):\n",
    "    pred_flat   = np.array(np.argmax(preds, axis=2).flatten())\n",
    "    labels_flat = np.array(labels.flatten())\n",
    "    return np.sum(pred_flat[labels_flat!=pad_index] == labels_flat[labels_flat!=pad_index]) / len(labels_flat[labels_flat!=pad_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4WoUld5L8Dz"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.colab import output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdddTTNoT8QG"
   },
   "outputs": [],
   "source": [
    "# Number of batches per epoch\n",
    "niter = len(list(enumerate(train_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a42Wy8B3j5J6"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YEZyT6KCK1Ch",
    "outputId": "c768f913-0663-45d5-89ca-bd15050e8ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on epoch 1\n",
      "Epoch 1/3 : Processed 50/1349 batches, elapsed time: 0:00:23.603158, remaining time in epoch: 0:10:13.160475\n",
      "Epoch 1/3 : Processed 100/1349 batches, elapsed time: 0:00:47.869139, remaining time in epoch: 0:09:57.861328\n",
      "Epoch 1/3 : Processed 150/1349 batches, elapsed time: 0:01:12.214282, remaining time in epoch: 0:09:37.217784\n",
      "Epoch 1/3 : Processed 200/1349 batches, elapsed time: 0:01:36.662213, remaining time in epoch: 0:09:15.312849\n",
      "Epoch 1/3 : Processed 250/1349 batches, elapsed time: 0:02:01.307265, remaining time in epoch: 0:08:53.257879\n",
      "Epoch 1/3 : Processed 300/1349 batches, elapsed time: 0:02:26.013936, remaining time in epoch: 0:08:30.555643\n",
      "Epoch 1/3 : Processed 350/1349 batches, elapsed time: 0:02:50.777435, remaining time in epoch: 0:08:07.442070\n",
      "Epoch 1/3 : Processed 400/1349 batches, elapsed time: 0:03:15.628844, remaining time in epoch: 0:07:44.124583\n",
      "Epoch 1/3 : Processed 450/1349 batches, elapsed time: 0:03:40.599404, remaining time in epoch: 0:07:20.705083\n",
      "Epoch 1/3 : Processed 500/1349 batches, elapsed time: 0:04:05.601879, remaining time in epoch: 0:06:57.028800\n",
      "Epoch 1/3 : Processed 550/1349 batches, elapsed time: 0:04:30.642483, remaining time in epoch: 0:06:33.167126\n",
      "Epoch 1/3 : Processed 600/1349 batches, elapsed time: 0:04:55.698431, remaining time in epoch: 0:06:09.128172\n",
      "Epoch 1/3 : Processed 650/1349 batches, elapsed time: 0:05:20.737770, remaining time in epoch: 0:05:44.914560\n",
      "Epoch 1/3 : Processed 700/1349 batches, elapsed time: 0:05:45.777274, remaining time in epoch: 0:05:20.583285\n",
      "Epoch 1/3 : Processed 750/1349 batches, elapsed time: 0:06:10.867388, remaining time in epoch: 0:04:56.197713\n",
      "Epoch 1/3 : Processed 800/1349 batches, elapsed time: 0:06:35.997262, remaining time in epoch: 0:04:31.751706\n",
      "Epoch 1/3 : Processed 850/1349 batches, elapsed time: 0:07:01.183654, remaining time in epoch: 0:04:07.258492\n",
      "Epoch 1/3 : Processed 900/1349 batches, elapsed time: 0:07:26.393829, remaining time in epoch: 0:03:42.699959\n",
      "Epoch 1/3 : Processed 950/1349 batches, elapsed time: 0:07:51.557697, remaining time in epoch: 0:03:18.053625\n",
      "Epoch 1/3 : Processed 1000/1349 batches, elapsed time: 0:08:16.763170, remaining time in epoch: 0:02:53.369589\n",
      "Epoch 1/3 : Processed 1050/1349 batches, elapsed time: 0:08:41.927439, remaining time in epoch: 0:02:28.624528\n",
      "Epoch 1/3 : Processed 1100/1349 batches, elapsed time: 0:09:07.101870, remaining time in epoch: 0:02:03.843636\n",
      "Epoch 1/3 : Processed 1150/1349 batches, elapsed time: 0:09:32.289292, remaining time in epoch: 0:01:39.030559\n",
      "Epoch 1/3 : Processed 1200/1349 batches, elapsed time: 0:09:57.458795, remaining time in epoch: 0:01:14.184269\n",
      "Epoch 1/3 : Processed 1250/1349 batches, elapsed time: 0:10:22.620530, remaining time in epoch: 0:00:49.311405\n",
      "Epoch 1/3 : Processed 1300/1349 batches, elapsed time: 0:10:47.813242, remaining time in epoch: 0:00:24.417484\n",
      "Train loss: 0.2255408446669711\n",
      "Saving checkpoint to: ner.dataset.transformers.0.pth\n",
      "Validation loss: 0.14925271429121495\n",
      "Validation Accuracy: 0.9539251606061958\n",
      "F1-Score: 0.7904539154539153\n",
      "Working on epoch 2\n",
      "Epoch 2/3 : Processed 50/1349 batches, elapsed time: 0:12:01.777272, remaining time in epoch: 0:10:37.983066\n",
      "Epoch 2/3 : Processed 100/1349 batches, elapsed time: 0:12:26.981236, remaining time in epoch: 0:10:21.511143\n",
      "Epoch 2/3 : Processed 150/1349 batches, elapsed time: 0:12:52.147601, remaining time in epoch: 0:09:58.917286\n",
      "Epoch 2/3 : Processed 200/1349 batches, elapsed time: 0:13:17.346491, remaining time in epoch: 0:09:35.223870\n",
      "Epoch 2/3 : Processed 250/1349 batches, elapsed time: 0:13:42.516162, remaining time in epoch: 0:09:10.799018\n",
      "Epoch 2/3 : Processed 300/1349 batches, elapsed time: 0:14:07.723035, remaining time in epoch: 0:08:46.257075\n",
      "Epoch 2/3 : Processed 350/1349 batches, elapsed time: 0:14:32.895505, remaining time in epoch: 0:08:21.426072\n",
      "Epoch 2/3 : Processed 400/1349 batches, elapsed time: 0:14:58.073237, remaining time in epoch: 0:07:56.523268\n",
      "Epoch 2/3 : Processed 450/1349 batches, elapsed time: 0:15:23.284454, remaining time in epoch: 0:07:31.625236\n",
      "Epoch 2/3 : Processed 500/1349 batches, elapsed time: 0:15:48.466152, remaining time in epoch: 0:07:06.614859\n",
      "Epoch 2/3 : Processed 550/1349 batches, elapsed time: 0:16:13.641428, remaining time in epoch: 0:06:41.563817\n",
      "Epoch 2/3 : Processed 600/1349 batches, elapsed time: 0:16:38.833194, remaining time in epoch: 0:06:16.513312\n",
      "Epoch 2/3 : Processed 650/1349 batches, elapsed time: 0:17:04.021466, remaining time in epoch: 0:05:51.436929\n",
      "Epoch 2/3 : Processed 700/1349 batches, elapsed time: 0:17:29.199289, remaining time in epoch: 0:05:26.334723\n",
      "Epoch 2/3 : Processed 750/1349 batches, elapsed time: 0:17:54.385664, remaining time in epoch: 0:05:01.229313\n",
      "Epoch 2/3 : Processed 800/1349 batches, elapsed time: 0:18:19.569805, remaining time in epoch: 0:04:36.112413\n",
      "Epoch 2/3 : Processed 850/1349 batches, elapsed time: 0:18:44.749283, remaining time in epoch: 0:04:10.984525\n",
      "Epoch 2/3 : Processed 900/1349 batches, elapsed time: 0:19:09.938388, remaining time in epoch: 0:03:45.855980\n",
      "Epoch 2/3 : Processed 950/1349 batches, elapsed time: 0:19:35.137314, remaining time in epoch: 0:03:20.724930\n",
      "Epoch 2/3 : Processed 1000/1349 batches, elapsed time: 0:20:00.316839, remaining time in epoch: 0:02:55.580504\n",
      "Epoch 2/3 : Processed 1050/1349 batches, elapsed time: 0:20:25.473963, remaining time in epoch: 0:02:30.426302\n",
      "Epoch 2/3 : Processed 1100/1349 batches, elapsed time: 0:20:50.704788, remaining time in epoch: 0:02:05.288583\n",
      "Epoch 2/3 : Processed 1150/1349 batches, elapsed time: 0:21:15.875752, remaining time in epoch: 0:01:40.132422\n",
      "Epoch 2/3 : Processed 1200/1349 batches, elapsed time: 0:21:41.067210, remaining time in epoch: 0:01:14.977694\n",
      "Epoch 2/3 : Processed 1250/1349 batches, elapsed time: 0:22:06.287662, remaining time in epoch: 0:00:49.822146\n",
      "Epoch 2/3 : Processed 1300/1349 batches, elapsed time: 0:22:31.448283, remaining time in epoch: 0:00:24.659348\n",
      "Train loss: 0.12840662343224568\n",
      "Saving checkpoint to: ner.dataset.transformers.1.pth\n",
      "Validation loss: 0.14177608686188856\n",
      "Validation Accuracy: 0.9565869878700869\n",
      "F1-Score: 0.8057484820687546\n",
      "Working on epoch 3\n",
      "Epoch 3/3 : Processed 50/1349 batches, elapsed time: 0:23:59.902283, remaining time in epoch: 0:10:35.157741\n",
      "Epoch 3/3 : Processed 100/1349 batches, elapsed time: 0:24:25.043697, remaining time in epoch: 0:10:19.371606\n",
      "Epoch 3/3 : Processed 150/1349 batches, elapsed time: 0:24:50.203684, remaining time in epoch: 0:09:57.496471\n",
      "Epoch 3/3 : Processed 200/1349 batches, elapsed time: 0:25:15.325797, remaining time in epoch: 0:09:33.761193\n",
      "Epoch 3/3 : Processed 250/1349 batches, elapsed time: 0:25:40.504800, remaining time in epoch: 0:09:09.721998\n",
      "Epoch 3/3 : Processed 300/1349 batches, elapsed time: 0:26:05.695862, remaining time in epoch: 0:08:45.344445\n",
      "Epoch 3/3 : Processed 350/1349 batches, elapsed time: 0:26:30.868710, remaining time in epoch: 0:08:20.682816\n",
      "Epoch 3/3 : Processed 400/1349 batches, elapsed time: 0:26:56.065100, remaining time in epoch: 0:07:55.949123\n",
      "Epoch 3/3 : Processed 450/1349 batches, elapsed time: 0:27:21.253465, remaining time in epoch: 0:07:31.096624\n",
      "Epoch 3/3 : Processed 500/1349 batches, elapsed time: 0:27:46.453469, remaining time in epoch: 0:07:06.196302\n",
      "Epoch 3/3 : Processed 550/1349 batches, elapsed time: 0:28:11.633824, remaining time in epoch: 0:06:41.213855\n",
      "Epoch 3/3 : Processed 600/1349 batches, elapsed time: 0:28:36.820806, remaining time in epoch: 0:06:16.205473\n",
      "Epoch 3/3 : Processed 650/1349 batches, elapsed time: 0:29:02.016392, remaining time in epoch: 0:05:51.179697\n",
      "Epoch 3/3 : Processed 700/1349 batches, elapsed time: 0:29:27.196156, remaining time in epoch: 0:05:26.114712\n",
      "Epoch 3/3 : Processed 750/1349 batches, elapsed time: 0:29:52.386855, remaining time in epoch: 0:05:01.043623\n",
      "Epoch 3/3 : Processed 800/1349 batches, elapsed time: 0:30:17.566877, remaining time in epoch: 0:04:35.949909\n",
      "Epoch 3/3 : Processed 850/1349 batches, elapsed time: 0:30:42.761311, remaining time in epoch: 0:04:10.854286\n"
     ]
    }
   ],
   "source": [
    "max_grad_norm  = 1.0\n",
    "dstart=datetime.now()\n",
    "for iepoch in range(epochs) : \n",
    "    print(\"Working on epoch %i\"%(iepoch+1))\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    ientry=0\n",
    "    tepoch_start = datetime.now()\n",
    "    for step, batch in enumerate(train_dataloader) :\n",
    "        ientry+=1\n",
    "        if ientry%50==0 :\n",
    "          tnow    = datetime.now()\n",
    "          remtime = ((tnow - tepoch_start)/ientry)*(niter-ientry)\n",
    "          print(\"Epoch %i/%i : Processed %i/%i batches, elapsed time: %s, remaining time in epoch: %s\"%(iepoch+1,epochs,\n",
    "                                                                                                        ientry,niter,\n",
    "                                                                                                        datetime.now()-dstart,remtime))\n",
    "\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss    = outputs[0]\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    # See: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    print(\"Saving checkpoint to: ner.dataset.transformers.%i.pth\"%(iepoch))\n",
    "    torch.save(model.state_dict(), \"/content/drive/My Drive/ner.dataset.transformers.%i.pth\"%(iepoch))\n",
    "\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "          outputs = model(b_input_ids, token_type_ids=None,\n",
    "                          attention_mask=b_input_mask, labels=b_labels)\n",
    "          tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        logits    = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # NOTE: Need to ignore padding when evaluating accuracy\n",
    "        # (NB: transformers does this already in loss function, but not\n",
    "        # pytorch-pretrained-bert==0.4.0 - this is a known bug)\n",
    "\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids, pad_index=tag2idx['[PAD]'])\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags  = np.array([tags_vals[p_i] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "\n",
    "    # Need to explicitly factor padding out of F1 score calculation\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred_tags[valid_tags!=['[PAD]']].tolist(), valid_tags[valid_tags!=['[PAD]']].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9iquCsE9Az-o"
   },
   "source": [
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dG_Ioxn0jwY6"
   },
   "source": [
    "# Reload the model and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgmDhMFbvcZN"
   },
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n",
    "model.load_state_dict(torch.load(\"/content/drive/My Drive/ner.dataset.transformers.1.pth\"))\n",
    "model.eval()\n",
    "model.cuda()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "911a5fc8ca1446a2a459657deb1b115c",
      "75e07e16907d44e7a8492e0066298ae2",
      "6e7417e2be2e46199f8b6c4c7df422f6",
      "cffe01e52aac4c42b48d6d33a64bccc6",
      "e8378538f4aa47f2adebebca5c90d8a2",
      "a3bbdd77ef6a4db8b0b6fc2edfdaa98a",
      "1534941565b043f99837328f331592ce",
      "28c2d8a466a74faeb16c0017909bc632"
     ]
    },
    "colab_type": "code",
    "id": "5J9p37PivpdW",
    "outputId": "633a97b6-07c4-4cd0-a323-da64a81a5eaf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911a5fc8ca1446a2a459657deb1b115c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         4\n",
      "       B-geo       0.84      0.92      0.88       393\n",
      "       B-gpe       0.95      0.92      0.94       158\n",
      "       B-nat       0.33      0.33      0.33         3\n",
      "       B-org       0.80      0.62      0.70       229\n",
      "       B-per       0.79      0.86      0.83       175\n",
      "       B-tim       0.95      0.91      0.93       238\n",
      "       I-art       0.00      0.00      0.00         6\n",
      "       I-eve       0.50      0.20      0.29         5\n",
      "       I-geo       0.79      0.82      0.81       254\n",
      "       I-gpe       0.83      0.56      0.67         9\n",
      "       I-nat       1.00      1.00      1.00         1\n",
      "       I-org       0.79      0.60      0.68       396\n",
      "       I-per       0.82      0.96      0.88       441\n",
      "       I-tim       0.84      0.71      0.77       113\n",
      "           O       0.98      0.99      0.99      9999\n",
      "\n",
      "    accuracy                           0.96     12428\n",
      "   macro avg       0.66      0.61      0.63     12428\n",
      "weighted avg       0.95      0.96      0.95     12428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "isent=0\n",
    "for i in tqdm(range(500)) : # tqdm(np.random.randint(0,len(val_inputs),500)) : # range(len(val_inputs))) :\n",
    "    input_ids       = torch.tensor([val_inputs[i].cpu().numpy()]).to(device)\n",
    "    tags            = torch.tensor([val_tags[i].cpu().numpy()]).to(device)\n",
    "    attention_masks = torch.tensor([val_masks[i].cpu().numpy()]).to(device)\n",
    "    \n",
    "    outputs   = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=tags)\n",
    "    loss, prediction_scores = outputs[:2]\n",
    "\n",
    "    ovar        = prediction_scores.cpu().detach().numpy()\n",
    "    pred_labels = np.array([np.argmax(ovar[0][j]) for j in range(len(ovar[0]))])  \n",
    "    noid_masks  = (input_ids[0]>0).detach().cpu().numpy()\n",
    "\n",
    "    y_true.extend(tags.cpu().numpy()[0][noid_masks].tolist())\n",
    "    y_pred.extend(pred_labels[noid_masks])\n",
    "    \n",
    "    isent+=1\n",
    "\n",
    "# Convert back to label representations\n",
    "y_true = [idx2tag[i] for i in y_true]\n",
    "y_pred = [idx2tag[i] for i in y_pred]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IX6DTq2FoSl1"
   },
   "source": [
    "# Reload analogous model from `pytorch-pretrained-bert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "aafe755380d5412b8a230f19271d461d",
      "bb1b70f3e5094720939e9142042a248e",
      "99a14cb810194271b2e54e5e93e1b5b2",
      "b35e9519b48f4a50bef9c0c85c56da87",
      "51df505ff2914fcba65cd22d99984a52",
      "8b0927f360d44a9a8e72766dcd20e00e",
      "a04d5033d0944ac28aaceec3402dd2f5",
      "b31d3c2c2cf04e16b7aeb376ef452da7"
     ]
    },
    "colab_type": "code",
    "id": "4n19losbm9Oz",
    "outputId": "a33f0a2b-6636-477e-ace1-2ba504f6d58e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:33: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c2fda4258d4f0c9c920e690317b718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-2.2406, -3.0015, -1.4142,  ..., -2.1016, -2.4216, 12.0613],\n",
      "         [-2.4263, -3.1180, -1.7738,  ..., -1.9558, -2.2086, 12.1448],\n",
      "         [-2.3871, -3.0961, -1.6323,  ..., -1.9416, -2.3062, 12.1193],\n",
      "         ...,\n",
      "         [-2.3336, -2.9671, -1.7897,  ..., -1.8481, -2.0898, 12.2888],\n",
      "         [-2.3318, -2.9709, -1.7947,  ..., -1.8535, -2.0813, 12.2904],\n",
      "         [-2.3335, -2.9719, -1.7941,  ..., -1.8620, -2.0559, 12.2922]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-66eceb637cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midx2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1899\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Some config variables\n",
    "# NOTE: Back when I trained this model I didn't have an explicit [PAD] label\n",
    "tag2idx = {'B-art': 0,\n",
    " 'B-eve': 1,\n",
    " 'B-geo': 2,\n",
    " 'B-gpe': 3,\n",
    " 'B-nat': 4,\n",
    " 'B-org': 5,\n",
    " 'B-per': 6,\n",
    " 'B-tim': 7,\n",
    " 'I-art': 8,\n",
    " 'I-eve': 9,\n",
    " 'I-geo': 10,\n",
    " 'I-gpe': 11,\n",
    " 'I-nat': 12,\n",
    " 'I-org': 13,\n",
    " 'I-per': 14,\n",
    " 'I-tim': 15,\n",
    " 'O': 16}\n",
    "\n",
    "# Reload the model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n",
    "model.load_state_dict(torch.load(\"ner.dataset.4.pth\",map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "# model.cuda()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "isent=0\n",
    "for i in tqdm(range(500)) : # tqdm(np.random.randint(0,len(val_inputs),500)) : # range(len(val_inputs))) :\n",
    "    input_ids       = torch.tensor([val_inputs[i].cpu().numpy()]).to(device)\n",
    "    tags            = torch.tensor([val_tags[i].cpu().numpy()]).to(device)\n",
    "    attention_masks = torch.tensor([val_masks[i].cpu().numpy()]).to(device)\n",
    "    \n",
    "    outputs   = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=tags)\n",
    "    loss, prediction_scores = outputs[:2]\n",
    "\n",
    "    ovar        = prediction_scores.cpu().detach().numpy()\n",
    "    pred_labels = np.array([np.argmax(ovar[0][j]) for j in range(len(ovar[0]))])  \n",
    "    noid_masks  = (input_ids[0]>0).detach().cpu().numpy()\n",
    "\n",
    "    y_true.extend(tags.cpu().numpy()[0][noid_masks].tolist())\n",
    "    y_pred.extend(pred_labels[noid_masks])\n",
    "    \n",
    "    isent+=1\n",
    "\n",
    "# Convert back to label representations\n",
    "y_true = [idx2tag[i] for i in y_true]\n",
    "y_pred = [idx2tag[i] for i in y_pred]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otrdgDSLBFJH"
   },
   "source": [
    "**Note:** Results appear to be within a few percent of the `tranformers` model, so the two seem to be in agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3C4DAzTjolCZ"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "C8LqCLfyHjM6",
    "outputId": "be0cb47e-655b-48df-9569-ef48815cdd14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.50      0.25      0.33         4\n",
      "       B-geo       0.87      0.92      0.90       393\n",
      "       B-gpe       0.98      0.92      0.95       158\n",
      "       B-nat       0.50      0.67      0.57         3\n",
      "       B-org       0.86      0.69      0.76       229\n",
      "       B-per       0.87      0.88      0.87       175\n",
      "       B-tim       0.99      0.92      0.96       238\n",
      "       I-art       0.00      0.00      0.00         6\n",
      "       I-eve       0.25      0.20      0.22         5\n",
      "       I-geo       0.86      0.84      0.85       254\n",
      "       I-gpe       1.00      0.56      0.71         9\n",
      "       I-nat       1.00      1.00      1.00         1\n",
      "       I-org       0.89      0.71      0.79       396\n",
      "       I-per       0.88      0.96      0.92       441\n",
      "       I-tim       0.97      0.73      0.83       113\n",
      "           O       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.84      2429\n",
      "   macro avg       0.67      0.60      0.63      2429\n",
      "weighted avg       0.89      0.84      0.86      2429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Let's also get the results without \"O\"\n",
    "y_true_filt = []\n",
    "y_pred_filt = []\n",
    "for i in range(len(y_true)) :\n",
    "    if y_true[i] == \"O\" : \n",
    "        continue\n",
    "    y_true_filt.append(y_true[i])\n",
    "    y_pred_filt.append(y_pred[i])\n",
    "    \n",
    "print(classification_report(y_true_filt, y_pred_filt))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_testing_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1534941565b043f99837328f331592ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28c2d8a466a74faeb16c0017909bc632": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a995fb3bf06439486737ef6ae877802": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d6ee1e99b7e41c3929286fe942c1756",
      "placeholder": "​",
      "style": "IPY_MODEL_568cbaf6b49f45c5b64ba03c85413933",
      "value": "100% 47959/47959 [00:57&lt;00:00, 834.71it/s]"
     }
    },
    "2cff490baa104a589aa4239ec411d7a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45fe15bedd464d88921fa6eaed2ff281",
      "max": 47959,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bac00e382bbc4d13b75ce6f3986393eb",
      "value": 47959
     }
    },
    "45fe15bedd464d88921fa6eaed2ff281": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51df505ff2914fcba65cd22d99984a52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "568cbaf6b49f45c5b64ba03c85413933": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "613dea0252b04d0abe651c695f4423de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cff490baa104a589aa4239ec411d7a6",
       "IPY_MODEL_2a995fb3bf06439486737ef6ae877802"
      ],
      "layout": "IPY_MODEL_eb0e2593a18d4554b880763879a2222a"
     }
    },
    "6e7417e2be2e46199f8b6c4c7df422f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3bbdd77ef6a4db8b0b6fc2edfdaa98a",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8378538f4aa47f2adebebca5c90d8a2",
      "value": 500
     }
    },
    "75e07e16907d44e7a8492e0066298ae2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b0927f360d44a9a8e72766dcd20e00e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d6ee1e99b7e41c3929286fe942c1756": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "911a5fc8ca1446a2a459657deb1b115c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e7417e2be2e46199f8b6c4c7df422f6",
       "IPY_MODEL_cffe01e52aac4c42b48d6d33a64bccc6"
      ],
      "layout": "IPY_MODEL_75e07e16907d44e7a8492e0066298ae2"
     }
    },
    "99a14cb810194271b2e54e5e93e1b5b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b0927f360d44a9a8e72766dcd20e00e",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51df505ff2914fcba65cd22d99984a52",
      "value": 500
     }
    },
    "a04d5033d0944ac28aaceec3402dd2f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3bbdd77ef6a4db8b0b6fc2edfdaa98a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aafe755380d5412b8a230f19271d461d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99a14cb810194271b2e54e5e93e1b5b2",
       "IPY_MODEL_b35e9519b48f4a50bef9c0c85c56da87"
      ],
      "layout": "IPY_MODEL_bb1b70f3e5094720939e9142042a248e"
     }
    },
    "b31d3c2c2cf04e16b7aeb376ef452da7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b35e9519b48f4a50bef9c0c85c56da87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b31d3c2c2cf04e16b7aeb376ef452da7",
      "placeholder": "​",
      "style": "IPY_MODEL_a04d5033d0944ac28aaceec3402dd2f5",
      "value": "100% 500/500 [00:07&lt;00:00, 70.87it/s]"
     }
    },
    "bac00e382bbc4d13b75ce6f3986393eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb1b70f3e5094720939e9142042a248e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cffe01e52aac4c42b48d6d33a64bccc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c2d8a466a74faeb16c0017909bc632",
      "placeholder": "​",
      "style": "IPY_MODEL_1534941565b043f99837328f331592ce",
      "value": "100% 500/500 [00:07&lt;00:00, 70.74it/s]"
     }
    },
    "e8378538f4aa47f2adebebca5c90d8a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb0e2593a18d4554b880763879a2222a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
